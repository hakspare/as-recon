#!/usr/bin/env python3
import requests, urllib3, sys, concurrent.futures, re, time, argparse, socket, hashlib, string
from random import choices

urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

C, G, Y, R, M, W, B = '\033[96m', '\033[92m', '\033[93m', '\033[91m', '\033[95m', '\033[0m', '\033[1m'

LOGO = f"""{C}{B}
   â–„â–„â–„Â· .â–„â–„ Â·      â–„â–„â–„â–„â–„â–„â–„â–„ . â–„â–„Â·       â– â–„ 
  â–â–ˆ â–€â–ˆ â–â–ˆ â–€. â–ª     â€¢â–ˆâ–ˆ  â–€â–„.â–€Â·â–â–ˆ â–„Â·â–ª     â€¢â–ˆâ–Œâ–â–ˆ
  â–„â–ˆâ–€â–€â–ˆ â–„â–€â–€â–€â–ˆâ–„ â–„â–ˆâ–€â–„  â–â–ˆ.â–ªâ–â–€â–€â–ªâ–„â–ˆâ–ˆâ–€â–€â–ˆâ–„â–ˆâ–€â–„  â–â–ˆâ–â–â–Œ
  â–â–ˆ â–ªâ–â–Œâ–â–ˆâ–„â–ªâ–â–ˆâ–â–ˆâ–Œ.â–â–Œ â–â–ˆâ–ŒÂ·â–â–ˆâ–„â–„â–Œâ–â–ˆ â–ªâ–â–ˆâ–â–ˆâ–Œ.â–â–Œâ–ˆâ–ˆâ–â–ˆâ–Œ
   â–€  â–€  â–€â–€â–€â–€  â–€â–ˆâ–„â–€â–ª â–€â–€â–€  â–€â–€â–€  â–€  â–€ â–€â–ˆâ–„â–€â–ªâ–€â–€ â–ˆâ–ª
{Y}        >> AS-RECON v10.2: Overlord Engine <<{W}
{G}      Developed by Ajijul Islam Shohan (@hakspare){W}
"""

def advanced_strict_filter(sub, target_domain):
    """
    ğŸ‘‰ à¦à¦‡ à¦«à¦¾à¦‚à¦¶à¦¨à¦Ÿà¦¿à¦‡ à¦†à¦ªà¦¨à¦¾à¦° à¦†à¦¸à¦² à¦«à¦¿à¦²à§à¦Ÿà¦¾à¦°à¥¤
    à¦à¦Ÿà¦¿ à¦šà§‡à¦• à¦•à¦°à§‡ à¦¸à¦¾à¦¬à¦¡à§‹à¦®à§‡à¦‡à¦¨à¦Ÿà¦¿ à¦•à¦¿ à¦†à¦¸à¦²à§‡à¦‡ target_domain à¦à¦° à¦…à¦‚à¦¶, à¦¨à¦¾à¦•à¦¿ à¦…à¦¨à§à¦¯ à¦•à§‹à¦¨à§‹ à¦¡à§‹à¦®à§‡à¦‡à¦¨ à¦¢à§à¦•à§‡ à¦—à§‡à¦›à§‡à¥¤
    """
    sub = sub.lower().strip().strip('.')
    if sub.startswith("*."): sub = sub[2:]

    # à§§. Noise Filtering: à¦¯à¦¦à¦¿ à¦¸à¦¾à¦¬à¦¡à§‹à¦®à§‡à¦‡à¦¨à§‡à¦° à¦­à§‡à¦¤à¦° à¦…à¦¨à§à¦¯ TLD à¦¥à¦¾à¦•à§‡ (à¦¯à§‡à¦®à¦¨ .com. .net. .org.)
    # target_domain à¦à¦° à¦¬à¦¾à¦‡à¦°à§‡ à¦•à§‹à¦¨à§‹ à¦¡à¦Ÿ à¦¥à¦¾à¦•à¦²à§‡ à¦¸à§‡à¦Ÿà¦¾ à¦¬à¦¾à¦¦à¥¤
    # à¦‰à¦¦à¦¾à¦¹à¦°à¦£: azprintbd.com.renesabazar.com à¦¬à¦¾à¦¦ à¦¯à¦¾à¦¬à§‡à¥¤
    check_pattern = r'^([a-z0-9-]+\.)+' + re.escape(target_domain) + '$'
    if not re.match(check_pattern, sub):
        return None

    # à§¨. Cross-Domain Leakage: à¦¸à¦¾à¦¬à¦¡à§‹à¦®à§‡à¦‡à¦¨ à¦ªà¦¾à¦°à§à¦Ÿà§‡ à¦¯à¦¦à¦¿ à¦à¦•à¦¾à¦§à¦¿à¦•à¦¬à¦¾à¦° à¦¡à§‹à¦®à§‡à¦‡à¦¨ à¦¨à¦¾à¦® à¦¥à¦¾à¦•à§‡
    if sub.count(target_domain) > 1:
        return None

    # à§©. Forbidden TLD Leak: à¦…à¦¨à§‡à¦• à¦¸à¦®à§Ÿ à¦¸à§‹à¦°à§à¦¸ à¦¥à§‡à¦•à§‡ à¦…à¦¨à§à¦¯ à¦¡à§‹à¦®à§‡à¦‡à¦¨ à¦²à¦¿à¦• à¦¹à§Ÿ
    forbidden = ['.com.', '.net.', '.org.', '.edu.', '.gov.', '.xyz.']
    if any(x in sub for x in forbidden):
        return None

    return sub

def fetch_source(url, domain):
    try:
        r = requests.get(url, headers={'User-Agent': 'Mozilla/5.0'}, timeout=12, verify=False)
        if r.status_code == 200:
            # à¦¸à¦¾à¦¬à¦¡à§‹à¦®à§‡à¦‡à¦¨ à¦–à§‹à¦à¦œà¦¾à¦° à¦œà¦¨à§à¦¯ à¦ªà¦¾à¦“à§Ÿà¦¾à¦°à¦«à§à¦² à¦ªà§à¦¯à¦¾à¦Ÿà¦¾à¦°à§à¦¨
            pattern = r'(?:[a-zA-Z0-9-]+\.)+' + re.escape(domain)
            raw_subs = re.findall(pattern, r.text)
            
            cleaned = set()
            for s in raw_subs:
                # à¦à¦–à¦¾à¦¨à§‡ à¦¹à¦¾à¦‡-à¦²à§‡à¦­à§‡à¦² à¦«à¦¿à¦²à§à¦Ÿà¦¾à¦° à¦•à¦² à¦•à¦°à¦¾ à¦¹à¦šà§à¦›à§‡
                valid_sub = advanced_strict_filter(s, domain)
                if valid_sub:
                    cleaned.add(valid_sub)
            return list(cleaned)
    except: pass
    return []

def main():
    parser = argparse.ArgumentParser(formatter_class=argparse.RawDescriptionHelpFormatter, description=LOGO, add_help=False)
    target_grp = parser.add_argument_group(f'{Y}TARGET OPTIONS{W}')
    target_grp.add_argument("-d", "--domain", required=True, help="Target domain")
    
    # Help option
    sys_grp = parser.add_argument_group(f'{Y}SYSTEM{W}')
    sys_grp.add_argument("-h", "--help", action="help", help="Show help")

    if len(sys.argv) == 1:
        print(LOGO); parser.print_help(); sys.exit()
        
    args = parser.parse_args()
    target = args.domain
    start_time = time.time()

    sources = [
        f"https://crt.sh/?q=%25.{target}",
        f"https://api.subdomain.center/api/index.php?domain={target}",
        f"https://otx.alienvault.com/api/v1/indicators/domain/{target}/passive_dns",
        f"https://api.hackertarget.com/hostsearch/?q={target}",
        f"https://jldc.me/anubis/subdomains/{target}"
    ]

    print(f"{C}[*] Initializing Ultra-Strict Filter on: {target}{W}")
    
    all_found = set()
    with concurrent.futures.ThreadPoolExecutor(max_workers=10) as executor:
        futures = {executor.submit(fetch_source, url, target): url for url in sources}
        for f in concurrent.futures.as_completed(futures):
            res = f.result()
            if res: all_found.update(res)

    final_results = sorted(list(all_found))

    if not final_results:
        print(f"{R}[!] No valid subdomains found after strict filtering.{W}")
    else:
        print(f"{G}[+]{W} Unique Cleaned Targets: {B}{len(final_results)}{W}\n")
        for s in final_results:
            print(f" {C}Â»{W} {s}")

    duration = round(time.time() - start_time, 2)
    print(f"\n{G}â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”{W}")
    print(f"{G}â”‚{W}  {B}SCAN SUMMARY (STRICT MODE){W}               {G}â”‚{W}")
    print(f"{G}â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤{W}")
    print(f"{G}â”‚{W}  {C}Total Cleaned :{W} {B}{len(final_results):<10}{W}             {G}â”‚{W}")
    print(f"{G}â”‚{W}  {C}Time Elapsed  :{W} {B}{duration:<10} seconds{W}     {G}â”‚{W}")
    print(f"{G}â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜{W}")

if __name__ == "__main__":
    main()
