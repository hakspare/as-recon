#!/usr/bin/env python3
import requests, urllib3, sys, concurrent.futures, re, time, argparse, socket, hashlib, string
from random import choices

urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

C, G, Y, R, M, W, B = '\033[96m', '\033[92m', '\033[93m', '\033[91m', '\033[95m', '\033[0m', '\033[1m'

LOGO = f"""{C}{B}
   â–„â–„â–„Â· .â–„â–„ Â·      â–„â–„â–„â–„â–„â–„â–„â–„ . â–„â–„Â·       â– â–„ 
  â–â–ˆ â–€â–ˆ â–â–ˆ â–€. â–ª     â€¢â–ˆâ–ˆ  â–€â–„.â–€Â·â–â–ˆ â–„Â·â–ª     â€¢â–ˆâ–Œâ–â–ˆ
  â–„â–ˆâ–€â–€â–ˆ â–„â–€â–€â–€â–ˆâ–„ â–„â–ˆâ–€â–„  â–â–ˆ.â–ªâ–â–€â–€â–ªâ–„â–ˆâ–ˆâ–€â–€â–ˆâ–„â–ˆâ–€â–„  â–â–ˆâ–â–â–Œ
  â–â–ˆ â–ªâ–â–Œâ–â–ˆâ–„â–ªâ–â–ˆâ–â–ˆâ–Œ.â–â–Œ â–â–ˆâ–ŒÂ·â–â–ˆâ–„â–„â–Œâ–â–ˆ â–ªâ–â–ˆâ–â–ˆâ–Œ.â–â–Œâ–ˆâ–ˆâ–â–ˆâ–Œ
   â–€  â–€  â–€â–€â–€â–€  â–€â–ˆâ–„â–€â–ª â–€â–€â–€  â–€â–€â–€  â–€  â–€ â–€â–ˆâ–„â–€â–ªâ–€â–€ â–ˆâ–ª
{Y}        >> AS-RECON v10.2: Overlord Engine <<{W}
{G}      Developed by Ajijul Islam Shohan (@hakspare){W}
"""

def clean_subdomain(sub, domain):
    """
    ğŸ‘‰ Strict Sanitizer: à¦­à§à¦² à¦¡à§‹à¦®à§‡à¦‡à¦¨ à¦²à¦¿à¦•à§‡à¦œ à¦à¦¬à¦‚ à¦¨à§‹à¦‡à¦œ à¦¡à¦¾à¦Ÿà¦¾ à¦«à¦¿à¦²à§à¦Ÿà¦¾à¦° à¦•à¦°à§‡à¥¤
    """
    sub = sub.lower().strip().strip('.')
    
    # à§§. à¦¸à¦¾à¦°à§à¦Ÿà¦¿à¦«à¦¿à¦•à§‡à¦Ÿ à¦¸à§à¦Ÿà¦¾à¦°/à¦“à§Ÿà¦¾à¦‡à¦²à§à¦¡à¦•à¦¾à¦°à§à¦¡ à¦°à¦¿à¦®à§à¦­à¦¾à¦²
    if sub.startswith("*."): sub = sub[2:]
    
    # à§¨. Noise Filtering: à¦¸à¦¾à¦¬à¦¡à§‹à¦®à§‡à¦‡à¦¨à§‡à¦° à¦®à¦¾à¦à¦–à¦¾à¦¨à§‡ à¦…à¦¨à§à¦¯ à¦•à§‹à¦¨à§‹ TLD (.com, .org) à¦¥à¦¾à¦•à¦²à§‡ à¦¬à¦¾à¦¦
    # à¦à¦Ÿà¦¿ azprintbd.com.renesabazar.com à¦à¦° à¦®à¦¤à§‹ à¦­à§à¦² à¦¡à¦¾à¦Ÿà¦¾ à¦¬à§à¦²à¦• à¦•à¦°à¦¬à§‡
    invalid_tlds = ['.com.', '.org.', '.net.', '.edu.', '.gov.', '.xyz.', '.info.']
    if any(tld in sub for tld in invalid_tlds):
        return None

    # à§©. à¦¡à¦¾à¦¬à¦² à¦¡à§‹à¦®à§‡à¦‡à¦¨ à¦¡à¦¿à¦Ÿà§‡à¦•à¦¶à¦¨ (target.com.target.com)
    if sub.count(domain) > 1:
        return None

    # à§ª. Regex Validation: à¦¶à§à¦§à§ à¦­à§à¦¯à¦¾à¦²à¦¿à¦¡ à¦•à§à¦¯à¦¾à¦°à§‡à¦•à§à¦Ÿà¦¾à¦° à¦à¦¬à¦‚ à¦¸à¦ à¦¿à¦• à¦¡à§‹à¦®à§‡à¦‡à¦¨ à¦«à¦°à¦®à§‡à¦Ÿ à¦¨à¦¿à¦¶à§à¦šà¦¿à¦¤ à¦•à¦°à¦¾
    pattern = re.compile(r'^([a-z0-9]([a-z0-9-]{0,61}[a-z0-9])?\.)+' + re.escape(domain) + '$')
    if not pattern.match(sub):
        return None
    
    # à§«. à¦¸à§‡à¦²à¦«-à¦¡à§‹à¦®à§‡à¦‡à¦¨ à¦«à¦¿à¦²à§à¦Ÿà¦¾à¦°
    if sub == domain:
        return None
        
    return sub

def fetch_source(url, domain):
    try:
        r = requests.get(url, headers={'User-Agent': 'Mozilla/5.0'}, timeout=10, verify=False)
        if r.status_code == 200:
            pattern = r'(?:[a-zA-Z0-9-]+\.)+' + re.escape(domain)
            raw_subs = re.findall(pattern, r.text)
            
            cleaned = set()
            for s in raw_subs:
                c = clean_subdomain(s, domain)
                if c: cleaned.add(c)
            return list(cleaned)
    except: pass
    return []

# ... [Intelligence Class and live check logic remains same] ...

def main():
    parser = argparse.ArgumentParser(formatter_class=argparse.RawDescriptionHelpFormatter, description=LOGO, add_help=False)
    target_grp = parser.add_argument_group(f'{Y}TARGET OPTIONS{W}')
    target_grp.add_argument("-d", "--domain", required=True, help="Domain to scan")
    
    mode_grp = parser.add_argument_group(f'{Y}SCAN MODES{W}')
    mode_grp.add_argument("--live", action="store_true", help="Check for live hosts")
    
    perf_grp = parser.add_argument_group(f'{Y}PERFORMANCE{W}')
    perf_grp.add_argument("-t", "--threads", type=int, default=60, help="Threads (Default: 60)")
    
    out_grp = parser.add_argument_group(f'{Y}OUTPUT{W}')
    out_grp.add_argument("-o", "--output", help="Save text results to file")
    
    sys_grp = parser.add_argument_group(f'{Y}SYSTEM{W}')
    sys_grp.add_argument("-h", "--help", action="help", help="Show advanced help menu")

    if len(sys.argv) == 1:
        print(LOGO); parser.print_help(); sys.exit()
    args = parser.parse_args()

    start_time = time.time()
    target = args.domain
    
    sources = [
        f"https://crt.sh/?q=%25.{target}",
        f"https://api.subdomain.center/api/index.php?domain={target}",
        f"https://otx.alienvault.com/api/v1/indicators/domain/{target}/passive_dns",
        f"https://api.hackertarget.com/hostsearch/?q={target}",
        f"https://jldc.me/anubis/subdomains/{target}"
    ]

    print(f"{B}{C}[*] Initializing Intelligence on: {target}{W}")
    
    raw_results = set()
    with concurrent.futures.ThreadPoolExecutor(max_workers=15) as executor:
        futures = {executor.submit(fetch_source, url, target): url for url in sources}
        for f in concurrent.futures.as_completed(futures):
            res = f.result()
            if res: raw_results.update(res)

    final_list = sorted(list(raw_results))

    if not final_list:
        print(f"{R}[!] No valid discovery data found.{W}")
    else:
        print(f"{G}[+]{W} Total Potential Targets: {B}{len(final_list)}{W}\n")
        for s in final_list:
            print(f" {C}Â»{W} {s}")

    duration = round(time.time() - start_time, 2)
    print(f"\n{G}â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”{W}")
    print(f"{G}â”‚{W}  {B}SCAN SUMMARY (v10.2){W}                     {G}â”‚{W}")
    print(f"{G}â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤{W}")
    print(f"{G}â”‚{W}  {C}Total Found   :{W} {B}{len(final_list):<10}{W}             {G}â”‚{W}")
    print(f"{G}â”‚{W}  {C}Time Elapsed  :{W} {B}{duration:<10} seconds{W}     {G}â”‚{W}")
    print(f"{G}â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜{W}")

if __name__ == "__main__":
    main()
